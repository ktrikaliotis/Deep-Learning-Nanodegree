{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "**Restart the kernel after running these cells**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install torch==1.12.0 torchdata==0.4.0 torchtext==0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import torchtext\\nimport pandas as pd\\nfrom torchtext.datasets import SQuAD1\\n\\n\\ndef loadDF1(path):\\n    # Load the train and validation data from the SQuAD1 dataset\\n    train_data, val_data = SQuAD1(path)\\n\\n    # Create a dictionary to store the questions and answers\\n    data_dict = {\\\"Question\\\": [], \\\"Answer\\\": []}\\n\\n    # Extract the questions and answers from the train and validation data\\n    for data in (train_data, val_data):\\n        for _, question, answers, _ in data:\\n            data_dict[\\\"Question\\\"].append(question)\\n            data_dict[\\\"Answer\\\"].append(answers[0])\\n\\n    # Convert the data dictionary to a pandas dataframe\\n    df = pd.DataFrame(data_dict)\\n\\n    return df\";\n",
       "                var nbb_formatted_code = \"import torchtext\\nimport pandas as pd\\nfrom torchtext.datasets import SQuAD1\\n\\n\\ndef loadDF1(path):\\n    # Load the train and validation data from the SQuAD1 dataset\\n    train_data, val_data = SQuAD1(path)\\n\\n    # Create a dictionary to store the questions and answers\\n    data_dict = {\\\"Question\\\": [], \\\"Answer\\\": []}\\n\\n    # Extract the questions and answers from the train and validation data\\n    for data in (train_data, val_data):\\n        for _, question, answers, _ in data:\\n            data_dict[\\\"Question\\\"].append(question)\\n            data_dict[\\\"Answer\\\"].append(answers[0])\\n\\n    # Convert the data dictionary to a pandas dataframe\\n    df = pd.DataFrame(data_dict)\\n\\n    return df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchtext\n",
    "import pandas as pd\n",
    "from torchtext.datasets import SQuAD1\n",
    "\n",
    "\n",
    "def loadDF(path):\n",
    "    # Load the train and validation data from the SQuAD1 dataset\n",
    "    train_data, val_data = SQuAD1(path)\n",
    "\n",
    "    # Create a dictionary to store the questions and answers\n",
    "    data_dict = {\"Question\": [], \"Answer\": []}\n",
    "\n",
    "    # Extract the questions and answers from the train and validation data\n",
    "    for data in (train_data, val_data):\n",
    "        for _, question, answers, _ in data:\n",
    "            data_dict[\"Question\"].append(question)\n",
    "            data_dict[\"Answer\"].append(answers[0])\n",
    "\n",
    "    # Convert the data dictionary to a pandas dataframe\n",
    "    df = pd.DataFrame(data_dict)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>How many publications voted The College Dropou...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>What was the name of the single off the debut ...</td>\n",
       "      <td>Jesus Walks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>What label did Kanye create following the succ...</td>\n",
       "      <td>GOOD Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>When was The College Dropout finally released?</td>\n",
       "      <td>February 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>What song was the second released off of Kanye...</td>\n",
       "      <td>\"Slow Jamz\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Question  \\\n",
       "0     To whom did the Virgin Mary allegedly appear i...   \n",
       "1     What is in front of the Notre Dame Main Building?   \n",
       "2     The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                     What is the Grotto at Notre Dame?   \n",
       "4     What sits on top of the Main Building at Notre...   \n",
       "...                                                 ...   \n",
       "5995  How many publications voted The College Dropou...   \n",
       "5996  What was the name of the single off the debut ...   \n",
       "5997  What label did Kanye create following the succ...   \n",
       "5998     When was The College Dropout finally released?   \n",
       "5999  What song was the second released off of Kanye...   \n",
       "\n",
       "                                       Answer  \n",
       "0                  Saint Bernadette Soubirous  \n",
       "1                   a copper statue of Christ  \n",
       "2                           the Main Building  \n",
       "3     a Marian place of prayer and reflection  \n",
       "4          a golden statue of the Virgin Mary  \n",
       "...                                       ...  \n",
       "5995                                        2  \n",
       "5996                              Jesus Walks  \n",
       "5997                               GOOD Music  \n",
       "5998                            February 2004  \n",
       "5999                              \"Slow Jamz\"  \n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# select only a portion of SQuAD1 dataset as it is really huge and Cuda runs out of memory\\ndata_df = loadDF1(\\\"data\\\").iloc[:6000, :]\\ndata_df\";\n",
       "                var nbb_formatted_code = \"# select only a portion of SQuAD1 dataset as it is really huge and Cuda runs out of memory\\ndata_df = loadDF1(\\\"data\\\").iloc[:6000, :]\\ndata_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select only a portion of SQuAD1 dataset as it is really huge and Cuda runs out of memory\n",
    "data_df = loadDF(\"data\").iloc[:6000, :]\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "< Saint Bernadette Soubirous\n",
      "\n",
      "> What is in front of the Notre Dame Main Building?\n",
      "< a copper statue of Christ\n",
      "\n",
      "> The Basilica of the Sacred heart at Notre Dame is beside to which structure?\n",
      "< the Main Building\n",
      "\n",
      "> What is the Grotto at Notre Dame?\n",
      "< a Marian place of prayer and reflection\n",
      "\n",
      "> What sits on top of the Main Building at Notre Dame?\n",
      "< a golden statue of the Virgin Mary\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# print the first 5 question-answer pairs after text preprocessing\\nfor idx, row in data_df.head(5).iterrows():\\n    question = \\\"\\\".join(row[\\\"Question\\\"])\\n    answer = \\\"\\\".join(row[\\\"Answer\\\"])\\n    print(f\\\"> {question}\\\\n< {answer}\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"# print the first 5 question-answer pairs after text preprocessing\\nfor idx, row in data_df.head(5).iterrows():\\n    question = \\\"\\\".join(row[\\\"Question\\\"])\\n    answer = \\\"\\\".join(row[\\\"Answer\\\"])\\n    print(f\\\"> {question}\\\\n< {answer}\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print the first 5 question-answer pairs \n",
    "for idx, row in data_df.head(5).iterrows():\n",
    "    question = \"\".join(row[\"Question\"])\n",
    "    answer = \"\".join(row[\"Answer\"])\n",
    "    print(f\"> {question}\\n< {answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data (clean, tokenize etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"import nltk\\nfrom nltk.corpus import stopwords\\nfrom nltk.stem import PorterStemmer\\nfrom nltk.tokenize import word_tokenize\\nimport string\\n\\nnltk.download(\\\"punkt\\\")\\nnltk.download(\\\"stopwords\\\")\\n\\nsnowball_stemmer = nltk.stem.snowball.SnowballStemmer(\\\"english\\\")\\n\\n\\ndef prepare_text1(sentence):\\n    # remove punctuations and convert to lowercase\\n    sentence = \\\"\\\".join([s.lower() for s in sentence if s not in string.punctuation])\\n    sentence = \\\" \\\".join(snowball_stemmer.stem(w) for w in sentence.split())\\n\\n    # tokenize the sentence\\n    tokens = nltk.tokenize.RegexpTokenizer(r\\\"\\\\w+\\\").tokenize(sentence)\\n\\n    return tokens\";\n",
       "                var nbb_formatted_code = \"import nltk\\nfrom nltk.corpus import stopwords\\nfrom nltk.stem import PorterStemmer\\nfrom nltk.tokenize import word_tokenize\\nimport string\\n\\nnltk.download(\\\"punkt\\\")\\nnltk.download(\\\"stopwords\\\")\\n\\nsnowball_stemmer = nltk.stem.snowball.SnowballStemmer(\\\"english\\\")\\n\\n\\ndef prepare_text1(sentence):\\n    # remove punctuations and convert to lowercase\\n    sentence = \\\"\\\".join([s.lower() for s in sentence if s not in string.punctuation])\\n    sentence = \\\" \\\".join(snowball_stemmer.stem(w) for w in sentence.split())\\n\\n    # tokenize the sentence\\n    tokens = nltk.tokenize.RegexpTokenizer(r\\\"\\\\w+\\\").tokenize(sentence)\\n\\n    return tokens\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "snowball_stemmer = nltk.stem.snowball.SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "def prepare_text(sentence):\n",
    "    # remove punctuations and convert to lowercase\n",
    "    sentence = \"\".join([s.lower() for s in sentence if s not in string.punctuation])\n",
    "    sentence = \" \".join(snowball_stemmer.stem(w) for w in sentence.split())\n",
    "\n",
    "    # tokenize the sentence\n",
    "    tokens = nltk.tokenize.RegexpTokenizer(r\"\\w+\").tokenize(sentence)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: to whom did the virgin mari alleg appear in 1858 in lourd franc\n",
      "A: saint bernadett soubir\n",
      "\n",
      "Q: what is in front of the notr dame main build\n",
      "A: a copper statu of christ\n",
      "\n",
      "Q: the basilica of the sacr heart at notr dame is besid to which structur\n",
      "A: the main build\n",
      "\n",
      "Q: what is the grotto at notr dame\n",
      "A: a marian place of prayer and reflect\n",
      "\n",
      "Q: what sit on top of the main build at notr dame\n",
      "A: a golden statu of the virgin mari\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# Tokenize the questions and answers in the DataFrame using the `prepare_text` function\\ndata_df[\\\"Question\\\"] = data_df[\\\"Question\\\"].apply(prepare_text1)\\ndata_df[\\\"Answer\\\"] = data_df[\\\"Answer\\\"].apply(prepare_text1)\\n\\n# Print the first 5 pairs of tokenized questions and answers\\nfor i in range(5):\\n    q_tokens = \\\" \\\".join(\\n        data_df.loc[i, \\\"Question\\\"]\\n    )  # Join the question tokens into a single string\\n    a_tokens = \\\" \\\".join(\\n        data_df.loc[i, \\\"Answer\\\"]\\n    )  # Join the answer tokens into a single string\\n    print(f\\\"Q: {q_tokens}\\\\nA: {a_tokens}\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"# Tokenize the questions and answers in the DataFrame using the `prepare_text` function\\ndata_df[\\\"Question\\\"] = data_df[\\\"Question\\\"].apply(prepare_text1)\\ndata_df[\\\"Answer\\\"] = data_df[\\\"Answer\\\"].apply(prepare_text1)\\n\\n# Print the first 5 pairs of tokenized questions and answers\\nfor i in range(5):\\n    q_tokens = \\\" \\\".join(\\n        data_df.loc[i, \\\"Question\\\"]\\n    )  # Join the question tokens into a single string\\n    a_tokens = \\\" \\\".join(\\n        data_df.loc[i, \\\"Answer\\\"]\\n    )  # Join the answer tokens into a single string\\n    print(f\\\"Q: {q_tokens}\\\\nA: {a_tokens}\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the questions and answers in the DataFrame using the `prepare_text` function\n",
    "data_df[\"Question\"] = data_df[\"Question\"].apply(prepare_text)\n",
    "data_df[\"Answer\"] = data_df[\"Answer\"].apply(prepare_text)\n",
    "\n",
    "# Print the first 5 pairs of tokenized questions and answers\n",
    "for i in range(5):\n",
    "    q_tokens = \" \".join(\n",
    "        data_df.loc[i, \"Question\"]\n",
    "    )  # Join the question tokens into a single string\n",
    "    a_tokens = \" \".join(\n",
    "        data_df.loc[i, \"Answer\"]\n",
    "    )  # Join the answer tokens into a single string\n",
    "    print(f\"Q: {q_tokens}\\nA: {a_tokens}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulate the data and return representative training and test dataset but also the corresponding pairs to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# define vocabulary classes for source and target sentences\\nsrc_token = 0\\ntrg_token = 1\\n\\n\\nclass build_vocab:\\n    def __init__(self):\\n        self.word2index = {\\\"\\\": src_token, \\\"\\\": trg_token}\\n        self.index2word = {src_token: \\\"\\\", trg_token: \\\"\\\"}\\n        self.word_count = len(self.word2index)\\n\\n    def add_words(self, sentc):\\n        # add new words to the vocabulary\\n        split_sentence = sentc.split(\\\" \\\")\\n        for word in split_sentence:\\n            if word not in self.word2index:\\n                self.word2index[word] = self.word_count\\n                self.index2word[self.word_count] = word\\n                self.word_count += 1\";\n",
       "                var nbb_formatted_code = \"# define vocabulary classes for source and target sentences\\nsrc_token = 0\\ntrg_token = 1\\n\\n\\nclass build_vocab:\\n    def __init__(self):\\n        self.word2index = {\\\"\\\": src_token, \\\"\\\": trg_token}\\n        self.index2word = {src_token: \\\"\\\", trg_token: \\\"\\\"}\\n        self.word_count = len(self.word2index)\\n\\n    def add_words(self, sentc):\\n        # add new words to the vocabulary\\n        split_sentence = sentc.split(\\\" \\\")\\n        for word in split_sentence:\\n            if word not in self.word2index:\\n                self.word2index[word] = self.word_count\\n                self.index2word[self.word_count] = word\\n                self.word_count += 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define vocabulary classes for source and target sentences\n",
    "src_token = 0\n",
    "trg_token = 1\n",
    "\n",
    "\n",
    "class build_vocab:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"\": src_token, \"\": trg_token}\n",
    "        self.index2word = {src_token: \"\", trg_token: \"\"}\n",
    "        self.word_count = len(self.word2index)\n",
    "\n",
    "    def add_words(self, sentc):\n",
    "        # add new words to the vocabulary\n",
    "        split_sentence = sentc.split(\" \")\n",
    "        for word in split_sentence:\n",
    "            if word not in self.word2index:\n",
    "                self.word2index[word] = self.word_count\n",
    "                self.index2word[self.word_count] = word\n",
    "                self.word_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"import torch\\n\\n# use GPU if available\\ndevice = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n\\n\\ndef to_tensor(vocab, sentc):\\n    # convert a sentence to a torch tensor of indices\\n    split_sentence = sentc.split(\\\" \\\")\\n    indices = [vocab.word2index[word] for word in split_sentence]\\n    indices.append(vocab.word2index[\\\"\\\"])\\n    return torch.Tensor(indices).long().to(device).view(-1, 1)\";\n",
       "                var nbb_formatted_code = \"import torch\\n\\n# use GPU if available\\ndevice = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n\\n\\ndef to_tensor(vocab, sentc):\\n    # convert a sentence to a torch tensor of indices\\n    split_sentence = sentc.split(\\\" \\\")\\n    indices = [vocab.word2index[word] for word in split_sentence]\\n    indices.append(vocab.word2index[\\\"\\\"])\\n    return torch.Tensor(indices).long().to(device).view(-1, 1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def to_tensor(vocab, sentc):\n",
    "    # convert a sentence to a torch tensor of indices\n",
    "    split_sentence = sentc.split(\" \")\n",
    "    indices = [vocab.word2index[word] for word in split_sentence]\n",
    "    indices.append(vocab.word2index[\"\"])\n",
    "    return torch.Tensor(indices).long().to(device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"import random\\n\\n\\ndef train_test_split(SRC, TRG, test_size=0.2, random_state=None):\\n    # concatenate each source and target sentence into a single string\\n    data_src_list = SRC.apply(lambda x: \\\" \\\".join(x)).to_list()\\n    data_trg_list = TRG.apply(lambda x: \\\" \\\".join(x)).to_list()\\n\\n    # merge source and target sentences into pairs\\n    pairs = [list(i) for i in zip(data_src_list, data_trg_list)]\\n\\n    # shuffle the pairs randomly\\n    if random_state is not None:\\n        random.seed(random_seed)\\n    #     random.shuffle(pairs)\\n\\n    # split the pairs into train and test sets\\n    num_pairs = len(pairs)\\n    split_idx = int(num_pairs * (1 - test_size))\\n    train_pairs, test_pairs = pairs[:split_idx], pairs[split_idx:]\\n\\n    # split the train and test pairs into separate source and target lists\\n    train_data_src, train_data_trg = zip(*train_pairs)\\n    test_data_src, test_data_trg = zip(*test_pairs)\\n\\n    # build vocabularies for source and target sentences\\n    src_vocab = build_vocab()\\n    trg_vocab = build_vocab()\\n\\n    for pair in pairs:\\n        src_vocab.add_words(pair[0])\\n        trg_vocab.add_words(pair[1])\\n\\n    # convert source and target sentences to tensors for training and testing\\n    SRC_train_dataset = [to_tensor(src_vocab, s) for s in train_data_src]\\n    TRG_train_dataset = [to_tensor(trg_vocab, t) for t in train_data_trg]\\n    SRC_test_dataset = test_data_src\\n    TRG_test_dataset = test_data_trg\\n\\n    return (\\n        SRC_train_dataset,\\n        SRC_test_dataset,\\n        TRG_train_dataset,\\n        TRG_test_dataset,\\n        pairs,\\n    )\";\n",
       "                var nbb_formatted_code = \"import random\\n\\n\\ndef train_test_split(SRC, TRG, test_size=0.2, random_state=None):\\n    # concatenate each source and target sentence into a single string\\n    data_src_list = SRC.apply(lambda x: \\\" \\\".join(x)).to_list()\\n    data_trg_list = TRG.apply(lambda x: \\\" \\\".join(x)).to_list()\\n\\n    # merge source and target sentences into pairs\\n    pairs = [list(i) for i in zip(data_src_list, data_trg_list)]\\n\\n    # shuffle the pairs randomly\\n    if random_state is not None:\\n        random.seed(random_seed)\\n    #     random.shuffle(pairs)\\n\\n    # split the pairs into train and test sets\\n    num_pairs = len(pairs)\\n    split_idx = int(num_pairs * (1 - test_size))\\n    train_pairs, test_pairs = pairs[:split_idx], pairs[split_idx:]\\n\\n    # split the train and test pairs into separate source and target lists\\n    train_data_src, train_data_trg = zip(*train_pairs)\\n    test_data_src, test_data_trg = zip(*test_pairs)\\n\\n    # build vocabularies for source and target sentences\\n    src_vocab = build_vocab()\\n    trg_vocab = build_vocab()\\n\\n    for pair in pairs:\\n        src_vocab.add_words(pair[0])\\n        trg_vocab.add_words(pair[1])\\n\\n    # convert source and target sentences to tensors for training and testing\\n    SRC_train_dataset = [to_tensor(src_vocab, s) for s in train_data_src]\\n    TRG_train_dataset = [to_tensor(trg_vocab, t) for t in train_data_trg]\\n    SRC_test_dataset = test_data_src\\n    TRG_test_dataset = test_data_trg\\n\\n    return (\\n        SRC_train_dataset,\\n        SRC_test_dataset,\\n        TRG_train_dataset,\\n        TRG_test_dataset,\\n        pairs,\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def train_test_split(SRC, TRG, test_size=0.2, random_state=None):\n",
    "    # concatenate each source and target sentence into a single string\n",
    "    data_src_list = SRC.apply(lambda x: \" \".join(x)).to_list()\n",
    "    data_trg_list = TRG.apply(lambda x: \" \".join(x)).to_list()\n",
    "\n",
    "    # merge source and target sentences into pairs\n",
    "    pairs = [list(i) for i in zip(data_src_list, data_trg_list)]\n",
    "\n",
    "    # shuffle the pairs randomly\n",
    "    if random_state is not None:\n",
    "        random.seed(random_seed)\n",
    "    #     random.shuffle(pairs)\n",
    "\n",
    "    # split the pairs into train and test sets\n",
    "    num_pairs = len(pairs)\n",
    "    split_idx = int(num_pairs * (1 - test_size))\n",
    "    train_pairs, test_pairs = pairs[:split_idx], pairs[split_idx:]\n",
    "\n",
    "    # split the train and test pairs into separate source and target lists\n",
    "    train_data_src, train_data_trg = zip(*train_pairs)\n",
    "    test_data_src, test_data_trg = zip(*test_pairs)\n",
    "\n",
    "    # build vocabularies for source and target sentences\n",
    "    src_vocab = build_vocab()\n",
    "    trg_vocab = build_vocab()\n",
    "\n",
    "    for pair in pairs:\n",
    "        src_vocab.add_words(pair[0])\n",
    "        trg_vocab.add_words(pair[1])\n",
    "\n",
    "    # convert source and target sentences to tensors for training and testing\n",
    "    SRC_train_dataset = [to_tensor(src_vocab, s) for s in train_data_src]\n",
    "    TRG_train_dataset = [to_tensor(trg_vocab, t) for t in train_data_trg]\n",
    "    SRC_test_dataset = test_data_src\n",
    "    TRG_test_dataset = test_data_trg\n",
    "\n",
    "    return (\n",
    "        SRC_train_dataset,\n",
    "        SRC_test_dataset,\n",
    "        TRG_train_dataset,\n",
    "        TRG_test_dataset,\n",
    "        pairs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 1200, 4800, 1200)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"(\\n    SRC_train_dataset,\\n    SRC_test_dataset,\\n    TRG_train_dataset,\\n    TRG_test_dataset,\\n    pairs,\\n) = train_test_split(data_df[\\\"Question\\\"], data_df[\\\"Answer\\\"], test_size=0.2)\\n\\nlen(SRC_train_dataset), len(SRC_test_dataset), len(TRG_train_dataset), len(\\n    TRG_test_dataset\\n)\";\n",
       "                var nbb_formatted_code = \"(\\n    SRC_train_dataset,\\n    SRC_test_dataset,\\n    TRG_train_dataset,\\n    TRG_test_dataset,\\n    pairs,\\n) = train_test_split(data_df[\\\"Question\\\"], data_df[\\\"Answer\\\"], test_size=0.2)\\n\\nlen(SRC_train_dataset), len(SRC_test_dataset), len(TRG_train_dataset), len(\\n    TRG_test_dataset\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(\n",
    "    SRC_train_dataset,\n",
    "    SRC_test_dataset,\n",
    "    TRG_train_dataset,\n",
    "    TRG_test_dataset,\n",
    "    pairs,\n",
    ") = train_test_split(data_df[\"Question\"], data_df[\"Answer\"], test_size=0.2)\n",
    "\n",
    "len(SRC_train_dataset), len(SRC_test_dataset), len(TRG_train_dataset), len(\n",
    "    TRG_test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the max target output and the Source and Target vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# calculate the max target length\\nmax_trg = 0\\nfor p in pairs:\\n    max_trg = len(p[1].split()) if len(p[1].split()) > max_trg else max_trg\\n\\n# build vocabularies for source and target sentences\\nsrc_vocab = build_vocab()\\ntrg_vocab = build_vocab()\\n\\nfor pair in pairs:\\n    src_vocab.add_words(pair[0])\\n    trg_vocab.add_words(pair[1])\\n\\nmax_trg\";\n",
       "                var nbb_formatted_code = \"# calculate the max target length\\nmax_trg = 0\\nfor p in pairs:\\n    max_trg = len(p[1].split()) if len(p[1].split()) > max_trg else max_trg\\n\\n# build vocabularies for source and target sentences\\nsrc_vocab = build_vocab()\\ntrg_vocab = build_vocab()\\n\\nfor pair in pairs:\\n    src_vocab.add_words(pair[0])\\n    trg_vocab.add_words(pair[1])\\n\\nmax_trg\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the max target length\n",
    "max_trg = 0\n",
    "for p in pairs:\n",
    "    max_trg = len(p[1].split()) if len(p[1].split()) > max_trg else max_trg\n",
    "\n",
    "# build vocabularies for source and target sentences\n",
    "src_vocab = build_vocab()\n",
    "trg_vocab = build_vocab()\n",
    "\n",
    "for pair in pairs:\n",
    "    src_vocab.add_words(pair[0])\n",
    "    trg_vocab.add_words(pair[1])\n",
    "\n",
    "max_trg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"import torch.nn as nn\\n\\n\\n# define the Encoder class, which inherits from the nn.Module class\\nclass Encoder(nn.Module):\\n    def __init__(self, input_size, hidden_size):\\n        super(Encoder, self).__init__()\\n\\n        self.input_size = input_size\\n        self.hidden_size = hidden_size\\n\\n        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\\n        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\\n\\n    # define the forward method, which takes in the input sequence, hidden state, and cell state\\n    def forward(self, input_seq, hidden, cell_state):\\n        embedded = self.embedding(input_seq)\\n        embedded = embedded.view(1, 1, -1)\\n        embedded, (hidden, cell_state) = self.lstm(embedded, (hidden, cell_state))\\n        return embedded, hidden, cell_state\\n\\n\\n# define the Decoder class, which also inherits from the nn.Module class\\nclass Decoder(nn.Module):\\n    def __init__(self, hidden_dim, output_dim):\\n        super(Decoder, self).__init__()\\n\\n        self.hidden_dim = hidden_dim\\n        self.output_dim = output_dim\\n\\n        self.embedding_layer = nn.Embedding(output_dim, hidden_dim)\\n        self.lstm_layer = nn.LSTM(hidden_dim, hidden_dim)\\n        self.fc_layer = nn.Linear(hidden_dim, output_dim)\\n        self.softmax_layer = nn.LogSoftmax(dim=1)\\n\\n    # define the forward method, which takes in the input sequence, hidden state, and cell state\\n    def forward(self, input_seq, hidden_state, cell_state):\\n        embedded_input = self.embedding_layer(input_seq)\\n        embedded_input = embedded_input.view(1, 1, -1)\\n        output, (hidden_state, cell_state) = self.lstm_layer(\\n            embedded_input, (hidden_state, cell_state)\\n        )\\n        output = self.softmax_layer(self.fc_layer(output[0]))\\n        return output, hidden_state, cell_state\\n\\n\\n# define the Seq2Seq class, which also inherits from the nn.Module class\\nclass Seq2Seq(nn.Module):\\n    def __init__(self, input_dim, hidden_dim, output_dim):\\n        super(Seq2Seq, self).__init__()\\n\\n        self.input_dim = input_dim\\n        self.hidden_dim = hidden_dim\\n        self.output_dim = output_dim\\n\\n        self.encoder = Encoder(self.input_dim, self.hidden_dim)\\n        self.decoder = Decoder(self.hidden_dim, self.output_dim)\\n\\n    # define the forward method, which takes in the source sequence, source length, target length, and teacher forcing probability\\n    def forward(self, src_seq, src_len, trg_len, teacher_forcing_prob=1):\\n        outputs = {\\\"decoder_output\\\": []}\\n\\n        encoder_hidden = torch.zeros([1, 1, self.hidden_dim]).to(\\n            device\\n        )  # 1 = number of LSTM layers\\n        encoder_cell = torch.zeros([1, 1, self.hidden_dim]).to(device)\\n\\n        for t in range(src_len):\\n            encoder_output, encoder_hidden, encoder_cell = self.encoder(\\n                src_seq[t], encoder_hidden, encoder_cell\\n            )\\n\\n        decoder_input = torch.Tensor([[0]]).long().to(device)\\n        decoder_hidden = encoder_hidden\\n\\n        for t in range(trg_len):\\n            decoder_output, decoder_hidden, encoder_cell = self.decoder(\\n                decoder_input, decoder_hidden, encoder_cell\\n            )\\n            outputs[\\\"decoder_output\\\"].append(decoder_output)\\n\\n            if self.training:\\n                decoder_input = (\\n                    target_tensor[t]\\n                    if random.random() > teacher_forcing_prob\\n                    else decoder_output.argmax(1)\\n                )  # teacher forcing\\n            else:\\n                _, top_index = decoder_output.data.topk(1)\\n                decoder_input = top_index.squeeze().detach()\\n\\n        return outputs\";\n",
       "                var nbb_formatted_code = \"import torch.nn as nn\\n\\n\\n# define the Encoder class, which inherits from the nn.Module class\\nclass Encoder(nn.Module):\\n    def __init__(self, input_size, hidden_size):\\n        super(Encoder, self).__init__()\\n\\n        self.input_size = input_size\\n        self.hidden_size = hidden_size\\n\\n        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\\n        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\\n\\n    # define the forward method, which takes in the input sequence, hidden state, and cell state\\n    def forward(self, input_seq, hidden, cell_state):\\n        embedded = self.embedding(input_seq)\\n        embedded = embedded.view(1, 1, -1)\\n        embedded, (hidden, cell_state) = self.lstm(embedded, (hidden, cell_state))\\n        return embedded, hidden, cell_state\\n\\n\\n# define the Decoder class, which also inherits from the nn.Module class\\nclass Decoder(nn.Module):\\n    def __init__(self, hidden_dim, output_dim):\\n        super(Decoder, self).__init__()\\n\\n        self.hidden_dim = hidden_dim\\n        self.output_dim = output_dim\\n\\n        self.embedding_layer = nn.Embedding(output_dim, hidden_dim)\\n        self.lstm_layer = nn.LSTM(hidden_dim, hidden_dim)\\n        self.fc_layer = nn.Linear(hidden_dim, output_dim)\\n        self.softmax_layer = nn.LogSoftmax(dim=1)\\n\\n    # define the forward method, which takes in the input sequence, hidden state, and cell state\\n    def forward(self, input_seq, hidden_state, cell_state):\\n        embedded_input = self.embedding_layer(input_seq)\\n        embedded_input = embedded_input.view(1, 1, -1)\\n        output, (hidden_state, cell_state) = self.lstm_layer(\\n            embedded_input, (hidden_state, cell_state)\\n        )\\n        output = self.softmax_layer(self.fc_layer(output[0]))\\n        return output, hidden_state, cell_state\\n\\n\\n# define the Seq2Seq class, which also inherits from the nn.Module class\\nclass Seq2Seq(nn.Module):\\n    def __init__(self, input_dim, hidden_dim, output_dim):\\n        super(Seq2Seq, self).__init__()\\n\\n        self.input_dim = input_dim\\n        self.hidden_dim = hidden_dim\\n        self.output_dim = output_dim\\n\\n        self.encoder = Encoder(self.input_dim, self.hidden_dim)\\n        self.decoder = Decoder(self.hidden_dim, self.output_dim)\\n\\n    # define the forward method, which takes in the source sequence, source length, target length, and teacher forcing probability\\n    def forward(self, src_seq, src_len, trg_len, teacher_forcing_prob=1):\\n        outputs = {\\\"decoder_output\\\": []}\\n\\n        encoder_hidden = torch.zeros([1, 1, self.hidden_dim]).to(\\n            device\\n        )  # 1 = number of LSTM layers\\n        encoder_cell = torch.zeros([1, 1, self.hidden_dim]).to(device)\\n\\n        for t in range(src_len):\\n            encoder_output, encoder_hidden, encoder_cell = self.encoder(\\n                src_seq[t], encoder_hidden, encoder_cell\\n            )\\n\\n        decoder_input = torch.Tensor([[0]]).long().to(device)\\n        decoder_hidden = encoder_hidden\\n\\n        for t in range(trg_len):\\n            decoder_output, decoder_hidden, encoder_cell = self.decoder(\\n                decoder_input, decoder_hidden, encoder_cell\\n            )\\n            outputs[\\\"decoder_output\\\"].append(decoder_output)\\n\\n            if self.training:\\n                decoder_input = (\\n                    target_tensor[t]\\n                    if random.random() > teacher_forcing_prob\\n                    else decoder_output.argmax(1)\\n                )  # teacher forcing\\n            else:\\n                _, top_index = decoder_output.data.topk(1)\\n                decoder_input = top_index.squeeze().detach()\\n\\n        return outputs\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# define the Encoder class, which inherits from the nn.Module class\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "\n",
    "    # define the forward method, which takes in the input sequence, hidden state, and cell state\n",
    "    def forward(self, input_seq, hidden, cell_state):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        embedded = embedded.view(1, 1, -1)\n",
    "        embedded, (hidden, cell_state) = self.lstm(embedded, (hidden, cell_state))\n",
    "        return embedded, hidden, cell_state\n",
    "\n",
    "\n",
    "# define the Decoder class, which also inherits from the nn.Module class\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(output_dim, hidden_dim)\n",
    "        self.lstm_layer = nn.LSTM(hidden_dim, hidden_dim)\n",
    "        self.fc_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax_layer = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    # define the forward method, which takes in the input sequence, hidden state, and cell state\n",
    "    def forward(self, input_seq, hidden_state, cell_state):\n",
    "        embedded_input = self.embedding_layer(input_seq)\n",
    "        embedded_input = embedded_input.view(1, 1, -1)\n",
    "        output, (hidden_state, cell_state) = self.lstm_layer(\n",
    "            embedded_input, (hidden_state, cell_state)\n",
    "        )\n",
    "        output = self.softmax_layer(self.fc_layer(output[0]))\n",
    "        return output, hidden_state, cell_state\n",
    "\n",
    "\n",
    "# define the Seq2Seq class, which also inherits from the nn.Module class\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.encoder = Encoder(self.input_dim, self.hidden_dim)\n",
    "        self.decoder = Decoder(self.hidden_dim, self.output_dim)\n",
    "\n",
    "    # define the forward method, which takes in the source sequence, source length, target length, and teacher forcing probability\n",
    "    def forward(self, src_seq, src_len, trg_len, teacher_forcing_prob=1):\n",
    "        outputs = {\"decoder_output\": []}\n",
    "\n",
    "        encoder_hidden = torch.zeros([1, 1, self.hidden_dim]).to(\n",
    "            device\n",
    "        )  # 1 = number of LSTM layers\n",
    "        encoder_cell = torch.zeros([1, 1, self.hidden_dim]).to(device)\n",
    "\n",
    "        for t in range(src_len):\n",
    "            encoder_output, encoder_hidden, encoder_cell = self.encoder(\n",
    "                src_seq[t], encoder_hidden, encoder_cell\n",
    "            )\n",
    "\n",
    "        decoder_input = torch.Tensor([[0]]).long().to(device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for t in range(trg_len):\n",
    "            decoder_output, decoder_hidden, encoder_cell = self.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_cell\n",
    "            )\n",
    "            outputs[\"decoder_output\"].append(decoder_output)\n",
    "\n",
    "            if self.training:\n",
    "                decoder_input = (\n",
    "                    target_tensor[t]\n",
    "                    if random.random() > teacher_forcing_prob\n",
    "                    else decoder_output.argmax(1)\n",
    "                )  # teacher forcing\n",
    "            else:\n",
    "                _, top_index = decoder_output.data.topk(1)\n",
    "                decoder_input = top_index.squeeze().detach()\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"lr = 0.01\\nhidden_dim = 128\\nepochs = 70\\nbatch_size = 128\";\n",
       "                var nbb_formatted_code = \"lr = 0.01\\nhidden_dim = 128\\nepochs = 70\\nbatch_size = 128\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 0.01\n",
    "hidden_dim = 128\n",
    "epochs = 70\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"seq2seq = Seq2Seq(src_vocab.word_count, hidden_dim, trg_vocab.word_count)\";\n",
       "                var nbb_formatted_code = \"seq2seq = Seq2Seq(src_vocab.word_count, hidden_dim, trg_vocab.word_count)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq2seq = Seq2Seq(src_vocab.word_count, hidden_dim, trg_vocab.word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"from sklearn.model_selection import KFold\\n\\n\\ndef train_model(\\n    source_data, target_data, model, num_epochs, batch_size, output_every, lr\\n):\\n    # move the model to the selected device\\n    model.to(device)\\n\\n    # initialize total training and validation losses to 0\\n    final_training_loss = 0\\n    final_validation_loss = 0\\n\\n    # initialize the loss\\n    loss = 0\\n\\n    # define the optimizer and criterion\\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\\n    criterion = nn.NLLLoss()\\n\\n    # use K-Fold cross-validation\\n    kf = KFold(n_splits=num_epochs, shuffle=True)\\n\\n    # iterate through each epoch\\n    for epoch, (train_idx, val_idx) in enumerate(kf.split(source_data), 1):\\n        # Set the model in training mode\\n        model.train()\\n\\n        # iterate through each batch in the training set\\n        for i in range(0, len(train_idx)):\\n            src = source_data[train_idx[i]]\\n            trg = target_data[train_idx[i]]\\n\\n            # forward pass through the model\\n            output = model(src, src.size(0), trg.size(0))\\n\\n            # calculate the loss\\n            current_loss = 0\\n            for s, t in zip(output[\\\"decoder_output\\\"], trg):\\n                current_loss += criterion(s, t)\\n\\n            loss += current_loss\\n            final_training_loss += current_loss.item() / trg.size(0)\\n\\n            # update the model parameters every batch_size iterations\\n            if i % batch_size == 0 or i == (len(train_idx) - 1):\\n                loss.backward()\\n                optimizer.step()\\n                optimizer.zero_grad()\\n                loss = 0\\n\\n        # set the model in evaluation mode\\n        model.eval()\\n\\n        # iterate through each batch in the validation set\\n        for i in range(0, len(val_idx)):\\n            src = source_data[val_idx[i]]\\n            trg = target_data[val_idx[i]]\\n\\n            # forward pass through the model\\n            output = model(src, src.size(0), trg.size(0))\\n\\n            # calculate the loss\\n            current_loss = 0\\n            for s, t in zip(output[\\\"decoder_output\\\"], trg):\\n                current_loss += criterion(s, t)\\n\\n            final_validation_loss += current_loss.item() / trg.size(0)\\n\\n        # print the training and validation losses every output_every epochs\\n        if epoch % output_every == 0:\\n            training_loss_average = final_training_loss / (\\n                len(train_idx) * output_every\\n            )\\n            validation_loss_average = final_validation_loss / (\\n                len(val_idx) * output_every\\n            )\\n            print(\\n                \\\"{}/{} Epoch  -  Training Loss = {:.4f}  -  Validation Loss = {:.4f}\\\".format(\\n                    epoch, num_epochs, training_loss_average, validation_loss_average\\n                )\\n            )\\n            final_training_loss = 0\\n            final_validation_loss = 0\";\n",
       "                var nbb_formatted_code = \"from sklearn.model_selection import KFold\\n\\n\\ndef train_model(\\n    source_data, target_data, model, num_epochs, batch_size, output_every, lr\\n):\\n    # move the model to the selected device\\n    model.to(device)\\n\\n    # initialize total training and validation losses to 0\\n    final_training_loss = 0\\n    final_validation_loss = 0\\n\\n    # initialize the loss\\n    loss = 0\\n\\n    # define the optimizer and criterion\\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\\n    criterion = nn.NLLLoss()\\n\\n    # use K-Fold cross-validation\\n    kf = KFold(n_splits=num_epochs, shuffle=True)\\n\\n    # iterate through each epoch\\n    for epoch, (train_idx, val_idx) in enumerate(kf.split(source_data), 1):\\n        # Set the model in training mode\\n        model.train()\\n\\n        # iterate through each batch in the training set\\n        for i in range(0, len(train_idx)):\\n            src = source_data[train_idx[i]]\\n            trg = target_data[train_idx[i]]\\n\\n            # forward pass through the model\\n            output = model(src, src.size(0), trg.size(0))\\n\\n            # calculate the loss\\n            current_loss = 0\\n            for s, t in zip(output[\\\"decoder_output\\\"], trg):\\n                current_loss += criterion(s, t)\\n\\n            loss += current_loss\\n            final_training_loss += current_loss.item() / trg.size(0)\\n\\n            # update the model parameters every batch_size iterations\\n            if i % batch_size == 0 or i == (len(train_idx) - 1):\\n                loss.backward()\\n                optimizer.step()\\n                optimizer.zero_grad()\\n                loss = 0\\n\\n        # set the model in evaluation mode\\n        model.eval()\\n\\n        # iterate through each batch in the validation set\\n        for i in range(0, len(val_idx)):\\n            src = source_data[val_idx[i]]\\n            trg = target_data[val_idx[i]]\\n\\n            # forward pass through the model\\n            output = model(src, src.size(0), trg.size(0))\\n\\n            # calculate the loss\\n            current_loss = 0\\n            for s, t in zip(output[\\\"decoder_output\\\"], trg):\\n                current_loss += criterion(s, t)\\n\\n            final_validation_loss += current_loss.item() / trg.size(0)\\n\\n        # print the training and validation losses every output_every epochs\\n        if epoch % output_every == 0:\\n            training_loss_average = final_training_loss / (\\n                len(train_idx) * output_every\\n            )\\n            validation_loss_average = final_validation_loss / (\\n                len(val_idx) * output_every\\n            )\\n            print(\\n                \\\"{}/{} Epoch  -  Training Loss = {:.4f}  -  Validation Loss = {:.4f}\\\".format(\\n                    epoch, num_epochs, training_loss_average, validation_loss_average\\n                )\\n            )\\n            final_training_loss = 0\\n            final_validation_loss = 0\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    source_data, target_data, model, num_epochs, batch_size, output_every, lr\n",
    "):\n",
    "    # move the model to the selected device\n",
    "    model.to(device)\n",
    "\n",
    "    # initialize total training and validation losses to 0\n",
    "    final_training_loss = 0\n",
    "    final_validation_loss = 0\n",
    "\n",
    "    # initialize the loss\n",
    "    loss = 0\n",
    "\n",
    "    # define the optimizer and criterion\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # use K-Fold cross-validation\n",
    "    kf = KFold(n_splits=num_epochs, shuffle=True)\n",
    "\n",
    "    # iterate through each epoch\n",
    "    for epoch, (train_idx, val_idx) in enumerate(kf.split(source_data), 1):\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "\n",
    "        # iterate through each batch in the training set\n",
    "        for i in range(0, len(train_idx)):\n",
    "            src = source_data[train_idx[i]]\n",
    "            trg = target_data[train_idx[i]]\n",
    "\n",
    "            # forward pass through the model\n",
    "            output = model(src, src.size(0), trg.size(0))\n",
    "\n",
    "            # calculate the loss\n",
    "            current_loss = 0\n",
    "            for s, t in zip(output[\"decoder_output\"], trg):\n",
    "                current_loss += criterion(s, t)\n",
    "\n",
    "            loss += current_loss\n",
    "            final_training_loss += current_loss.item() / trg.size(0)\n",
    "\n",
    "            # update the model parameters every batch_size iterations\n",
    "            if i % batch_size == 0 or i == (len(train_idx) - 1):\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                loss = 0\n",
    "\n",
    "        # set the model in evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # iterate through each batch in the validation set\n",
    "        for i in range(0, len(val_idx)):\n",
    "            src = source_data[val_idx[i]]\n",
    "            trg = target_data[val_idx[i]]\n",
    "\n",
    "            # forward pass through the model\n",
    "            output = model(src, src.size(0), trg.size(0))\n",
    "\n",
    "            # calculate the loss\n",
    "            current_loss = 0\n",
    "            for s, t in zip(output[\"decoder_output\"], trg):\n",
    "                current_loss += criterion(s, t)\n",
    "\n",
    "            final_validation_loss += current_loss.item() / trg.size(0)\n",
    "\n",
    "        # print the training and validation losses every output_every epochs\n",
    "        if epoch % output_every == 0:\n",
    "            training_loss_average = final_training_loss / (\n",
    "                len(train_idx) * output_every\n",
    "            )\n",
    "            validation_loss_average = final_validation_loss / (\n",
    "                len(val_idx) * output_every\n",
    "            )\n",
    "            print(\n",
    "                \"{}/{} Epoch  -  Training Loss = {:.4f}  -  Validation Loss = {:.4f}\".format(\n",
    "                    epoch, num_epochs, training_loss_average, validation_loss_average\n",
    "                )\n",
    "            )\n",
    "            final_training_loss = 0\n",
    "            final_validation_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/70 Epoch  -  Training Loss = 5.9434  -  Validation Loss = 5.7051\n",
      "10/70 Epoch  -  Training Loss = 5.3602  -  Validation Loss = 5.2128\n",
      "15/70 Epoch  -  Training Loss = 5.1354  -  Validation Loss = 5.1155\n",
      "20/70 Epoch  -  Training Loss = 4.7919  -  Validation Loss = 4.8140\n",
      "25/70 Epoch  -  Training Loss = 4.3363  -  Validation Loss = 4.3695\n",
      "30/70 Epoch  -  Training Loss = 3.7777  -  Validation Loss = 3.9699\n",
      "35/70 Epoch  -  Training Loss = 3.1183  -  Validation Loss = 3.6024\n",
      "40/70 Epoch  -  Training Loss = 2.4468  -  Validation Loss = 2.7335\n",
      "45/70 Epoch  -  Training Loss = 1.7866  -  Validation Loss = 2.2015\n",
      "50/70 Epoch  -  Training Loss = 1.1642  -  Validation Loss = 1.4879\n",
      "55/70 Epoch  -  Training Loss = 0.6709  -  Validation Loss = 0.8617\n",
      "60/70 Epoch  -  Training Loss = 0.3799  -  Validation Loss = 0.5668\n",
      "65/70 Epoch  -  Training Loss = 0.2134  -  Validation Loss = 0.3143\n",
      "70/70 Epoch  -  Training Loss = 0.1270  -  Validation Loss = 0.1540\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"train_model(\\n    source_data=SRC_train_dataset,\\n    target_data=TRG_train_dataset,\\n    model=seq2seq,\\n    output_every=5,\\n    num_epochs=epochs,\\n    lr=lr,\\n    batch_size=batch_size,\\n)\";\n",
       "                var nbb_formatted_code = \"train_model(\\n    source_data=SRC_train_dataset,\\n    target_data=TRG_train_dataset,\\n    model=seq2seq,\\n    output_every=5,\\n    num_epochs=epochs,\\n    lr=lr,\\n    batch_size=batch_size,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(\n",
    "    source_data=SRC_train_dataset,\n",
    "    target_data=TRG_train_dataset,\n",
    "    model=seq2seq,\n",
    "    output_every=5,\n",
    "    num_epochs=epochs,\n",
    "    lr=lr,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5082, 128)\n",
       "    (lstm): LSTM(128, 128)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding_layer): Embedding(5201, 128)\n",
       "    (lstm_layer): LSTM(128, 128)\n",
       "    (fc_layer): Linear(in_features=128, out_features=5201, bias=True)\n",
       "    (softmax_layer): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"import torch\\n\\n# define the file path for saving the model\\nmodel_path = \\\"seq2seq.pt\\\"\\n\\n# save the trained Seq2Seq model\\ntorch.save(seq2seq, model_path)\\n\\n# load the saved Seq2Seq model and set it to evaluation mode\\nseq2seq = torch.load(model_path, map_location=torch.device(\\\"cuda\\\"))\\nseq2seq.eval()\";\n",
       "                var nbb_formatted_code = \"import torch\\n\\n# define the file path for saving the model\\nmodel_path = \\\"seq2seq.pt\\\"\\n\\n# save the trained Seq2Seq model\\ntorch.save(seq2seq, model_path)\\n\\n# load the saved Seq2Seq model and set it to evaluation mode\\nseq2seq = torch.load(model_path, map_location=torch.device(\\\"cuda\\\"))\\nseq2seq.eval()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# define the file path for saving the model\n",
    "model_path = \"seq2seq.pt\"\n",
    "\n",
    "# save the trained Seq2Seq model\n",
    "torch.save(seq2seq, model_path)\n",
    "\n",
    "# load the saved Seq2Seq model and set it to evaluation mode\n",
    "seq2seq = torch.load(model_path, map_location=torch.device(\"cuda\"))\n",
    "seq2seq.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"def model_eval(src, src_vocab, trg_vocab, model, trg_max_len):\\n    try:\\n        src = to_tensor(src_vocab, \\\" \\\".join(prepare_text1(src)))\\n    except:\\n        print(\\\"Can you please explain to me what do you mean?\\\")\\n        return\\n\\n    asnwer = []\\n\\n    output = model(src, src.size(0), trg_max_len)\\n\\n    for tensor in output[\\\"decoder_output\\\"]:\\n        _, top_token = tensor.data.topk(1)\\n        if top_token.item() == 1:\\n            break\\n        else:\\n            word = trg_vocab.index2word[top_token.item()]\\n            asnwer.append(word)\\n\\n    print(\\\"<\\\", \\\" \\\".join(asnwer), \\\"\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"def model_eval(src, src_vocab, trg_vocab, model, trg_max_len):\\n    try:\\n        src = to_tensor(src_vocab, \\\" \\\".join(prepare_text1(src)))\\n    except:\\n        print(\\\"Can you please explain to me what do you mean?\\\")\\n        return\\n\\n    asnwer = []\\n\\n    output = model(src, src.size(0), trg_max_len)\\n\\n    for tensor in output[\\\"decoder_output\\\"]:\\n        _, top_token = tensor.data.topk(1)\\n        if top_token.item() == 1:\\n            break\\n        else:\\n            word = trg_vocab.index2word[top_token.item()]\\n            asnwer.append(word)\\n\\n    print(\\\"<\\\", \\\" \\\".join(asnwer), \\\"\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model_eval(src, src_vocab, trg_vocab, model, trg_max_len):\n",
    "    try:\n",
    "        src = to_tensor(src_vocab, \" \".join(prepare_text(src)))\n",
    "    except:\n",
    "        print(\"Can you please explain to me what do you mean?\")\n",
    "        return\n",
    "\n",
    "    asnwer = []\n",
    "\n",
    "    output = model(src, src.size(0), trg_max_len)\n",
    "\n",
    "    for tensor in output[\"decoder_output\"]:\n",
    "        _, top_token = tensor.data.topk(1)\n",
    "        if top_token.item() == 1:\n",
    "            break\n",
    "        else:\n",
    "            word = trg_vocab.index2word[top_token.item()]\n",
    "            asnwer.append(word)\n",
    "\n",
    "    print(\"<\", \" \".join(asnwer), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate it in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input --> in 2007 which presid award lee the presidenti medal of freedom\n",
      "Expected --> georg w bush\n",
      "Predicted: \n",
      "< georg w \n",
      "\n",
      "\n",
      "\n",
      "Input --> a movi adapt of the book was releas in what year\n",
      "Expected --> 1962\n",
      "Predicted: \n",
      "Can you please explain to me what do you mean?\n",
      "\n",
      "\n",
      "Input --> who play atticus finch in the 1962 movi of the same titl\n",
      "Expected --> gregori peck\n",
      "Predicted: \n",
      "< tom \n",
      "\n",
      "\n",
      "\n",
      "Input --> which actor receiv an oscar for his role of atticus finch in the 1962 movi of the book\n",
      "Expected --> gregori peck\n",
      "Predicted: \n",
      "< mayella and \n",
      "\n",
      "\n",
      "\n",
      "Input --> what item did lee give the actor gregori peck after portray atticus finch\n",
      "Expected --> father pocketwatch\n",
      "Predicted: \n",
      "< lenox hill hospit \n",
      "\n",
      "\n",
      "\n",
      "Input --> which one of gregori peck relat was name after harper lee\n",
      "Expected --> grandson\n",
      "Predicted: \n",
      "< beyoncé \n",
      "\n",
      "\n",
      "\n",
      "Input --> what person effect did lee give to peck\n",
      "Expected --> her father pocketwatch\n",
      "Predicted: \n",
      "< woyciechowski \n",
      "\n",
      "\n",
      "\n",
      "Input --> which one of peck relat was name harper in honor of lee\n",
      "Expected --> grandson\n",
      "Predicted: \n",
      "< beyoncé z \n",
      "\n",
      "\n",
      "\n",
      "Input --> when did lee random show up at the los angel public librari\n",
      "Expected --> may 2005\n",
      "Predicted: \n",
      "< 2013 \n",
      "\n",
      "\n",
      "\n",
      "Input --> what did peck widow call lee\n",
      "Expected --> a nation treasur\n",
      "Predicted: \n",
      "< civil east \n",
      "\n",
      "\n",
      "\n",
      "Input --> who turn the novel into a play\n",
      "Expected --> christoph sergel\n",
      "Predicted: \n",
      "< harper lee \n",
      "\n",
      "\n",
      "\n",
      "Input --> when was the play for to kill a mockingbird first perform\n",
      "Expected --> 1990\n",
      "Predicted: \n",
      "< 1971 \n",
      "\n",
      "\n",
      "\n",
      "Input --> what town label itself the literari capit of alabama\n",
      "Expected --> monroevill\n",
      "Predicted: \n",
      "< the karmapa kargyu of china \n",
      "\n",
      "\n",
      "\n",
      "Input --> who make up the cast of the annual play base on the book perform in monroevill\n",
      "Expected --> townspeopl\n",
      "Predicted: \n",
      "Can you please explain to me what do you mean?\n",
      "\n",
      "\n",
      "Input --> dure the courtroom scene what happen to the audienc\n",
      "Expected --> racial segreg\n",
      "Predicted: \n",
      "< general help \n",
      "\n",
      "\n",
      "\n",
      "Input --> what countri did sergel play tour around in and perform in 2006\n",
      "Expected --> the uk\n",
      "Predicted: \n",
      "< one \n",
      "\n",
      "\n",
      "\n",
      "Input --> the play was the open act for the start of the 2013 season at which locat\n",
      "Expected --> regent park open air theatr\n",
      "Predicted: \n",
      "< roosevelt island \n",
      "\n",
      "\n",
      "\n",
      "Input --> who play atticus finch in the uk theater product of the film in 2006 and 2011\n",
      "Expected --> duncan preston\n",
      "Predicted: \n",
      "< mayella \n",
      "\n",
      "\n",
      "\n",
      "Input --> when was go set a watchman introduc to the public\n",
      "Expected --> juli 14 2015\n",
      "Predicted: \n",
      "< 2014 \n",
      "\n",
      "\n",
      "\n",
      "Input --> go set a watchman was finish in what year\n",
      "Expected --> 1957\n",
      "Predicted: \n",
      "< 1940 \n",
      "\n",
      "\n",
      "\n",
      "Input --> how mani year after to kill a mockingbird is the set of go set a watchman\n",
      "Expected --> 20\n",
      "Predicted: \n",
      "< 30 \n",
      "\n",
      "\n",
      "\n",
      "Input --> who was harper lee lawyer\n",
      "Expected --> tonja carter\n",
      "Predicted: \n",
      "< alic lee \n",
      "\n",
      "\n",
      "\n",
      "Input --> what is the earlier draft of the book titl\n",
      "Expected --> go set a watchman\n",
      "Predicted: \n",
      "< great of crazi in love \n",
      "\n",
      "\n",
      "\n",
      "Input --> what year was watchman complet\n",
      "Expected --> 1957\n",
      "Predicted: \n",
      "< 1952 \n",
      "\n",
      "\n",
      "\n",
      "Input --> how mani year after mockingbird was watchman set\n",
      "Expected --> 20\n",
      "Predicted: \n",
      "< six \n",
      "\n",
      "\n",
      "\n",
      "Input --> what two serious moral issu are dealt with in the novel\n",
      "Expected --> rape and racial inequ\n",
      "Predicted: \n",
      "< bozeman and forc \n",
      "\n",
      "\n",
      "\n",
      "Input --> who is the protagonist of the novel\n",
      "Expected --> atticus finch\n",
      "Predicted: \n",
      "< atticus atticus \n",
      "\n",
      "\n",
      "\n",
      "Input --> what is lee strongest style of write\n",
      "Expected --> narrat\n",
      "Predicted: \n",
      "< father jame \n",
      "\n",
      "\n",
      "\n",
      "Input --> what narrat techniqu doe lee use to combin the adult perspect with the child observ\n",
      "Expected --> flashback\n",
      "Predicted: \n",
      "< charl \n",
      "\n",
      "\n",
      "\n",
      "Input --> accord to lee her book simpli express a christian code of honor and conduct inherit to whom\n",
      "Expected --> all southern\n",
      "Predicted: \n",
      "< phage rariti \n",
      "\n",
      "\n",
      "\n",
      "Input --> besid the children fascin with boo the first part of the book was concern about their feel for what\n",
      "Expected --> the neighborhood\n",
      "Predicted: \n",
      "< spectr villag \n",
      "\n",
      "\n",
      "\n",
      "Input --> lee detail explan of the charact behavior caus one writer to catagor the book as what\n",
      "Expected --> southern romant region\n",
      "Predicted: \n",
      "< activewear \n",
      "\n",
      "\n",
      "\n",
      "Input --> scout defin peopl do the best they could with what they had as who\n",
      "Expected --> fine folk\n",
      "Predicted: \n",
      "< the kobylańska \n",
      "\n",
      "\n",
      "\n",
      "Input --> what drive the plot of the book more than the charact\n",
      "Expected --> the south itself\n",
      "Predicted: \n",
      "< jean billion \n",
      "\n",
      "\n",
      "\n",
      "Input --> who is the main exampl of an innoc destroy in the novel\n",
      "Expected --> tom robinson\n",
      "Predicted: \n",
      "< the fourth region \n",
      "\n",
      "\n",
      "\n",
      "Input --> what doe scout see symbol as a mockingbird\n",
      "Expected --> boo radley\n",
      "Predicted: \n",
      "< southern \n",
      "\n",
      "\n",
      "\n",
      "Input --> accord to atticus most peopl are how when you truli view them\n",
      "Expected --> real nice\n",
      "Predicted: \n",
      "< crazi in love \n",
      "\n",
      "\n",
      "\n",
      "Input --> review r a dave classifi the novel how\n",
      "Expected --> classic tragedi\n",
      "Predicted: \n",
      "< romant era \n",
      "\n",
      "\n",
      "\n",
      "Input --> what newspap wrote that the novel has strong contemporari nation signific\n",
      "Expected --> the chicago sunday tribun\n",
      "Predicted: \n",
      "Can you please explain to me what do you mean?\n",
      "\n",
      "\n",
      "Input --> which review call the book melodramat and contriv\n",
      "Expected --> granvill hick\n",
      "Predicted: \n",
      "< brush of and \n",
      "\n",
      "\n",
      "\n",
      "Input --> which southern writer deem it a child book\n",
      "Expected --> flanneri oconnor\n",
      "Predicted: \n",
      "< scout atticus and scout \n",
      "\n",
      "\n",
      "\n",
      "Input --> chimamanda ngozi adichi vompar lee to whom\n",
      "Expected --> william faulkner\n",
      "Predicted: \n",
      "< her mother \n",
      "\n",
      "\n",
      "\n",
      "Input --> rosemari gore connect lee to whom\n",
      "Expected --> jane austen\n",
      "Predicted: \n",
      "< grand a beyoncé \n",
      "\n",
      "\n",
      "\n",
      "Input --> who critic lee in the wall street journal\n",
      "Expected --> allen barra\n",
      "Predicted: \n",
      "< calpurnia rais \n",
      "\n",
      "\n",
      "\n",
      "Input --> who wrote that the book forc reader to question issu without resolv them\n",
      "Expected --> akin ajayi\n",
      "Predicted: \n",
      "< mold and generat \n",
      "\n",
      "\n",
      "\n",
      "Input --> which charact has some critic deem a variat of a content slave\n",
      "Expected --> calpurnia\n",
      "Predicted: \n",
      "< kodak replac collect \n",
      "\n",
      "\n",
      "\n",
      "Input --> accord to one consult which group found the book demor\n",
      "Expected --> black student\n",
      "Predicted: \n",
      "< her mother \n",
      "\n",
      "\n",
      "\n",
      "Input --> michael lund critic the novel for demon whom\n",
      "Expected --> poor rural white trash\n",
      "Predicted: \n",
      "< may 12 \n",
      "\n",
      "\n",
      "\n",
      "Input --> accord to dian mcwhorter everi child in the south had to face what\n",
      "Expected --> the harsh realiti of inequ\n",
      "Predicted: \n",
      "< survivor \n",
      "\n",
      "\n",
      "\n",
      "Input --> mcwhorter wrote that the exist of the book was what\n",
      "Expected --> an act of protest\n",
      "Predicted: \n",
      "< atticus \n",
      "\n",
      "\n",
      "\n",
      "Input --> how do the citizen of monroevill quot line of the book\n",
      "Expected --> like scriptur\n",
      "Predicted: \n",
      "Can you please explain to me what do you mean?\n",
      "\n",
      "\n",
      "Input --> what do the monroevill townspeopl call tourist to their town\n",
      "Expected --> mockingbird groupi\n",
      "Predicted: \n",
      "Can you please explain to me what do you mean?\n",
      "\n",
      "\n",
      "Input --> where doe solar energi come from\n",
      "Expected --> the sun\n",
      "Predicted: \n",
      "< japan \n",
      "\n",
      "\n",
      "\n",
      "Input --> what kind of energi consist of the light and heat provid by the sun\n",
      "Expected --> solar energi\n",
      "Predicted: \n",
      "< ign \n",
      "\n",
      "\n",
      "\n",
      "Input --> what technolog are use to har solar energi from the sun\n",
      "Expected --> solar heat photovolta solar thermal energi solar architectur and artifici photosynthesi\n",
      "Predicted: \n",
      "< an relief commiss \n",
      "\n",
      "\n",
      "\n",
      "Input --> what is solar energi\n",
      "Expected --> radiant light and heat from the sun\n",
      "Predicted: \n",
      "< his \n",
      "\n",
      "\n",
      "\n",
      "Input --> how mani terawatt of solar radiat doe the earth receiv\n",
      "Expected --> 174000\n",
      "Predicted: \n",
      "< 10 \n",
      "\n",
      "\n",
      "\n",
      "Input --> what percentag of solar radiat is reflect back by the atmospher\n",
      "Expected --> 30\n",
      "Predicted: \n",
      "Can you please explain to me what do you mean?\n",
      "\n",
      "\n",
      "Input --> the area that peopl live in typic receiv what rang of kwhm2 per day\n",
      "Expected --> 35 to 70\n",
      "Predicted: \n",
      "< duke to \n",
      "\n",
      "\n",
      "\n",
      "Input --> how mani terrawatt of radiat doe the earth receiv\n",
      "Expected --> 174000\n",
      "Predicted: \n",
      "< 30000 \n",
      "\n",
      "\n",
      "\n",
      "Input --> how much of the solar radiat is reflect back into space\n",
      "Expected --> approxim 30\n",
      "Predicted: \n",
      "< eight million \n",
      "\n",
      "\n",
      "\n",
      "Input --> what are the insol level of most popul area\n",
      "Expected --> 150 to 300 watt per squar meter or 35 to 70 kwhm2 per day\n",
      "Predicted: \n",
      "< democrat and behavior \n",
      "\n",
      "\n",
      "\n",
      "Input --> where is the solar radiat not reflect back to space absorb\n",
      "Expected --> cloud ocean and land mass\n",
      "Predicted: \n",
      "< nintendo \n",
      "\n",
      "\n",
      "\n",
      "Input --> the earth ocean cover what percentag of the globe\n",
      "Expected --> 71\n",
      "Predicted: \n",
      "< 1565 \n",
      "\n",
      "\n",
      "\n",
      "Input --> what is the averag temperatur of the earth surfac in celsius\n",
      "Expected --> 14\n",
      "Predicted: \n",
      "< 64 \n",
      "\n",
      "\n",
      "\n",
      "Input --> what is the process by which green plant convert solar energi to store energi\n",
      "Expected --> photosynthesi\n",
      "Predicted: \n",
      "< august 24 \n",
      "\n",
      "\n",
      "\n",
      "Input --> how much of the earth is cover by ocean\n",
      "Expected --> about 71\n",
      "Predicted: \n",
      "< 2000 million \n",
      "\n",
      "\n",
      "\n",
      "Input --> what is the caus of atmospher circul\n",
      "Expected --> warm air contain evapor water from the ocean rise\n",
      "Predicted: \n",
      "Can you please explain to me what do you mean?\n",
      "\n",
      "\n",
      "Input --> how doe the water vapor that rise in warm air turn into cloud\n",
      "Expected --> when the air reach a high altitud where the temperatur is low water vapor condens into cloud\n",
      "Predicted: \n",
      "< one \n",
      "\n",
      "\n",
      "\n",
      "Input --> what creat wind cyclon and anticyclon\n",
      "Expected --> the latent heat of water condens amplifi convect\n",
      "Predicted: \n",
      "< bacteri polonais \n",
      "\n",
      "\n",
      "\n",
      "Input --> what is the process in which plant convert solar energi into store energi call\n",
      "Expected --> photosynthesi\n",
      "Predicted: \n",
      "< earthquak predict the earthquak in the earthquak \n",
      "\n",
      "\n",
      "\n",
      "Input --> each year the earth absorb how much solar energi in exajoul\n",
      "Expected --> 3850000\n",
      "Predicted: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< 1971 \n",
      "\n",
      "\n",
      "\n",
      "Input --> in 2002 the sun provid more energi in one hour than human use in what span of time\n",
      "Expected --> one year\n",
      "Predicted: \n",
      "< horseback combat \n",
      "\n",
      "\n",
      "\n",
      "Input --> how much energi in exajoul doe photosynthesi captur each year\n",
      "Expected --> 3000\n",
      "Predicted: \n",
      "< 220 million \n",
      "\n",
      "\n",
      "\n",
      "Input --> twice the amount of energi obtain by all the nonrenew sourc on earth can be provid by the sun in what span of time\n",
      "Expected --> one year\n",
      "Predicted: \n",
      "< 14 \n",
      "\n",
      "\n",
      "\n",
      "Input --> what is the amount of solar energi absorb by the earth\n",
      "Expected --> approxim 3850000 exajoul ej per year\n",
      "Predicted: \n",
      "< 2005 \n",
      "\n",
      "\n",
      "\n",
      "Input --> how much solar energi is captur by photosynthesi\n",
      "Expected --> approxim 3000 ej per year\n",
      "Predicted: \n",
      "< 21 \n",
      "\n",
      "\n",
      "\n",
      "Input --> the amount of solar energi per year is twice as much as the energi that will ever be produc from what resourc\n",
      "Expected --> coal oil natur gas and mine uranium combin\n",
      "Predicted: \n",
      "< 20 \n",
      "\n",
      "\n",
      "\n",
      "Input --> where do the major of renew energi deriv their energi from\n",
      "Expected --> the sun\n",
      "Predicted: \n",
      "< donat of beichuan counti \n",
      "\n",
      "\n",
      "\n",
      "Input --> how are solar technolog defin\n",
      "Expected --> passiv or activ\n",
      "Predicted: \n",
      "< about \n",
      "\n",
      "\n",
      "\n",
      "Input --> what is one way that character solar technolog as passiv or activ\n",
      "Expected --> depend on the way they captur convert and distribut sunlight\n",
      "Predicted: \n",
      "< four \n",
      "\n",
      "\n",
      "\n",
      "Input --> which renew energi do not acquir their energi from the sun\n",
      "Expected --> geotherm and tidal\n",
      "Predicted: \n",
      "< peter counti of the dead \n",
      "\n",
      "\n",
      "\n",
      "Input --> how do renew energi acquir energi from the sun\n",
      "Expected --> direct or indirect\n",
      "Predicted: \n",
      "< a a chines the year of neighbor \n",
      "\n",
      "\n",
      "\n",
      "Input --> are suppli side solar technolog general activ or passiv\n",
      "Expected --> activ\n",
      "Predicted: \n",
      "< ipg \n",
      "\n",
      "\n",
      "\n",
      "Input --> are demand side solar technolog general activ or passiv\n",
      "Expected --> passiv\n",
      "Predicted: \n",
      "< ipg \n",
      "\n",
      "\n",
      "\n",
      "Input --> what is an activ solar techniqu use to generat energi\n",
      "Expected --> solar thermal collector\n",
      "Predicted: \n",
      "< seventh \n",
      "\n",
      "\n",
      "\n",
      "Input --> what is an activ solar techniqu use to generat energi\n",
      "Expected --> design space that natur circul air\n",
      "Predicted: \n",
      "< seventh \n",
      "\n",
      "\n",
      "\n",
      "Input --> what doe an activ solar techniqu do\n",
      "Expected --> increas the suppli of energi\n",
      "Predicted: \n",
      "< seventh \n",
      "\n",
      "\n",
      "\n",
      "Input --> what doe a passiv solar techniqu do\n",
      "Expected --> reduc the need for altern resourc\n",
      "Predicted: \n",
      "< koji \n",
      "\n",
      "\n",
      "\n",
      "Input --> what was the name of the inventor who built a solar engin in 1897\n",
      "Expected --> frank shuman\n",
      "Predicted: \n",
      "< 40 \n",
      "\n",
      "\n",
      "\n",
      "Input --> in what year was the sun power compani form\n",
      "Expected --> 1908\n",
      "Predicted: \n",
      "< 1626 \n",
      "\n",
      "\n",
      "\n",
      "Input --> shuman patent his solar engin system in what year\n",
      "Expected --> 1912\n",
      "Predicted: \n",
      "< 1624 \n",
      "\n",
      "\n",
      "\n",
      "Input --> who is frank shuman\n",
      "Expected --> a us inventor engin and solar energi pioneer\n",
      "Predicted: \n",
      "< adam emperor \n",
      "\n",
      "\n",
      "\n",
      "Input --> in what year did solar engin build his solar engin\n",
      "Expected --> 1897\n",
      "Predicted: \n",
      "< 2005 \n",
      "\n",
      "\n",
      "\n",
      "Input --> what was the solar engin use to power\n",
      "Expected --> steam engin\n",
      "Predicted: \n",
      "< 1909 \n",
      "\n",
      "\n",
      "\n",
      "Input --> in what year was the sun power compani establish\n",
      "Expected --> 1908\n",
      "Predicted: \n",
      "< 1927 \n",
      "\n",
      "\n",
      "\n",
      "Input --> in what year did frank shuman patent his solar engin\n",
      "Expected --> 1912\n",
      "Predicted: \n",
      "< 2005 \n",
      "\n",
      "\n",
      "\n",
      "Input --> where did shuman build the world first solar thermal power station\n",
      "Expected --> maadi egypt\n",
      "Predicted: \n",
      "< manhattan \n",
      "\n",
      "\n",
      "\n",
      "Input --> how mani liter of water per minut did shuman engin pump in litr\n",
      "Expected --> 22000\n",
      "Predicted: \n",
      "< one \n",
      "\n",
      "\n",
      "\n",
      "Input --> in what decad were shuman idea about solar energi reviv\n",
      "Expected --> the 1970s\n",
      "Predicted: \n",
      "< 1735 generat \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"for question, exp_answer in zip(SRC_test_dataset[:100], TRG_test_dataset[:100]):\\n    print(f\\\"Input --> {question}\\\")\\n    print(f\\\"Expected --> {exp_answer}\\\")\\n    print(\\\"Predicted: \\\")\\n    model_eval(question, src_vocab, trg_vocab, seq2seq, max_trg)\\n    print(\\\"\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"for question, exp_answer in zip(SRC_test_dataset[:100], TRG_test_dataset[:100]):\\n    print(f\\\"Input --> {question}\\\")\\n    print(f\\\"Expected --> {exp_answer}\\\")\\n    print(\\\"Predicted: \\\")\\n    model_eval(question, src_vocab, trg_vocab, seq2seq, max_trg)\\n    print(\\\"\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for question, exp_answer in zip(SRC_test_dataset[:100], TRG_test_dataset[:100]):\n",
    "    print(f\"Input --> {question}\")\n",
    "    print(f\"Expected --> {exp_answer}\")\n",
    "    print(\"Predicted: \")\n",
    "    model_eval(question, src_vocab, trg_vocab, seq2seq, max_trg)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate it in manual user's input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5458"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"random.randint(1,6000)\";\n",
       "                var nbb_formatted_code = \"random.randint(1, 6000)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.randint(1, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                    Answer  \n",
       "0               Saint Bernadette Soubirous  \n",
       "1                a copper statue of Christ  \n",
       "2                        the Main Building  \n",
       "3  a Marian place of prayer and reflection  \n",
       "4       a golden statue of the Virgin Mary  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"data_df_raw.head(5)\";\n",
       "                var nbb_formatted_code = \"data_df_raw.head(5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> How was she dressed on the cover of L'Officiel?\n",
      "< in blackface and tribal makeup\n",
      "\n",
      "> Where did Frédéric and Sand venture to after Majorca became unlivable when it was discovered they were not married?\n",
      "< Valldemossa\n",
      "\n",
      "> How many square miles are land in NYC?\n",
      "< 304.8\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# data_df_raw = loadDF(\\\"data\\\").iloc[:6000, :]\\n\\n# print 3 random question-answer pairs to test\\nfor idx, row in data_df_raw.iloc[random.sample(range(1, 6000), 3), :].iterrows():\\n    question = \\\"\\\".join(row[\\\"Question\\\"])\\n    answer = \\\"\\\".join(row[\\\"Answer\\\"])\\n    print(f\\\"> {question}\\\\n< {answer}\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"# data_df_raw = loadDF(\\\"data\\\").iloc[:6000, :]\\n\\n# print 3 random question-answer pairs to test\\nfor idx, row in data_df_raw.iloc[random.sample(range(1, 6000), 3), :].iterrows():\\n    question = \\\"\\\".join(row[\\\"Question\\\"])\\n    answer = \\\"\\\".join(row[\\\"Answer\\\"])\\n    print(f\\\"> {question}\\\\n< {answer}\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data_df_raw = loadDF(\"data\").iloc[:6000, :]\n",
    "\n",
    "# print 3 random question-answer pairs to test\n",
    "for idx, row in data_df_raw.iloc[random.sample(range(1, 6000), 3), :].iterrows():\n",
    "    question = \"\".join(row[\"Question\"])\n",
    "    answer = \"\".join(row[\"Answer\"])\n",
    "    print(f\"> {question}\\n< {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 'stop' to stop the chat interaction\n",
      "-----------------------------------\n",
      "\n",
      "> How was she dressed on the cover of L'Officiel?\n",
      "< in blackfac and tribal makeup \n",
      "\n",
      "> How many square miles are land in NYC?\n",
      "< 3048 \n",
      "\n",
      "> Where did Frédéric and Sand venture to after Majorca became unlivable when it was discovered they were not married?\n",
      "< valldemossa \n",
      "\n",
      "> stop\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"print(f\\\"Write 'stop' to stop the chat interaction\\\\n{'-'* 35}\\\\n\\\")\\nwhile True:\\n    src_input = input(\\\"> \\\")\\n    if src_input.strip() == \\\"stop\\\":\\n        break\\n    model_eval(src_input, src_vocab, trg_vocab, seq2seq, max_trg)\";\n",
       "                var nbb_formatted_code = \"print(f\\\"Write 'stop' to stop the chat interaction\\\\n{'-'* 35}\\\\n\\\")\\nwhile True:\\n    src_input = input(\\\"> \\\")\\n    if src_input.strip() == \\\"stop\\\":\\n        break\\n    model_eval(src_input, src_vocab, trg_vocab, seq2seq, max_trg)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Write 'stop' to stop the chat interaction\\n{'-'* 35}\\n\")\n",
    "while True:\n",
    "    src_input = input(\"> \")\n",
    "    if src_input.strip() == \"stop\":\n",
    "        break\n",
    "    model_eval(src_input, src_vocab, trg_vocab, seq2seq, max_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
